Certainly! Below are Python code snippets for each of the specified tasks:

### Q1. KNN Classifier on `load_iris` Dataset:
```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load iris dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=3)

# Fit the model
knn_classifier.fit(X_train, y_train)

# Make predictions
y_pred = knn_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
```

### Q2. KNN Regressor on `load_boston` Dataset:
```python
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

# Load boston dataset
boston = load_boston()
X, y = boston.data, boston.target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize KNN regressor
knn_regressor = KNeighborsRegressor(n_neighbors=5)

# Fit the model
knn_regressor.fit(X_train, y_train)

# Make predictions
y_pred = knn_regressor.predict(X_test)

# Calculate mean squared error
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
```

### Q3. Find Optimal Value of K for KNN Classifier on `load_iris`:
```python
from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {'n_neighbors': list(range(1, 21))}

# Initialize KNN classifier
knn_classifier = KNeighborsClassifier()

# Initialize GridSearchCV
grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')

# Fit the model
grid_search.fit(X, y)

# Print the best value of k
print(f'Optimal Value of K: {grid_search.best_params_["n_neighbors"]}')
```

### Q4. KNN Regressor with Feature Scaling on `load_boston`:
```python
from sklearn.preprocessing import StandardScaler

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize KNN regressor
knn_regressor_scaled = KNeighborsRegressor(n_neighbors=5)

# Fit the model with scaled features
knn_regressor_scaled.fit(X_train_scaled, y_train)

# Make predictions
y_pred_scaled = knn_regressor_scaled.predict(X_test_scaled)

# Calculate mean squared error
mse_scaled = mean_squared_error(y_test, y_pred_scaled)
print(f'Mean Squared Error with Feature Scaling: {mse_scaled}')
```

### Q5. KNN Classifier with Weighted Voting on `load_iris`:
```python
# Initialize KNN classifier with weighted voting
knn_classifier_weighted = KNeighborsClassifier(n_neighbors=3, weights='distance')

# Fit the model
knn_classifier_weighted.fit(X_train, y_train)

# Make predictions
y_pred_weighted = knn_classifier_weighted.predict(X_test)

# Calculate accuracy
accuracy_weighted = accuracy_score(y_test, y_pred_weighted)
print(f'Accuracy with Weighted Voting: {accuracy_weighted}')
```

### Q6. Function to Standardize Features before Applying KNN Classifier:
```python
def knn_classifier_with_scaling(X_train, X_test, y_train, y_test, n_neighbors=3):
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)
    knn_classifier.fit(X_train_scaled, y_train)

    y_pred = knn_classifier.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy

# Example usage:
accuracy_with_scaling = knn_classifier_with_scaling(X_train, X_test, y_train, y_test, n_neighbors=5)
print(f'Accuracy with Scaling: {accuracy_with_scaling}')
```

### Q7. Function to Calculate Euclidean Distance:
```python
import numpy as np

def euclidean_distance(point1, point2):
    return np.sqrt(np.sum((point1 - point2)**2))

# Example usage:
distance = euclidean_distance(np.array([1, 2, 3]), np.array([4, 5, 6]))
print(f'Euclidean Distance: {distance}')
```

### Q8. Function to Calculate Manhattan Distance:
```python
def manhattan_distance(point1, point2):
    return np.sum(np.abs(point1 - point2))

# Example usage:
distance_manhattan = manhattan_distance(np.array([1, 2, 3]), np.array([4, 5, 6]))
print(f'Manhattan Distance: {distance_manhattan}')
```

These code snippets cover the specified tasks. Feel free to adapt and integrate them into your Jupyter notebook as needed.